\chapter{関連研究}
%A Survey on Virtual Machine Migration:Challenges, Techniques and Open Issues
%４章a
この章では,本研究に関する関連研究について述べる.本研究と関連研究の差異を示し,本研究の必
要性について議論していく.この章では,3 つの関連研究について述べていく.

通常の Pre-copy 手法での移送では，ダーティレートがネットワーク転送速度よりも高い場合，
ダーティページの反復転送が収束せず，移送時間が長期化したり，ダウンタイムが増加するという課題がある．
以降の節では，この問題に対して異なるアプローチで最適化を行っている．

\section{XBRLE}
XOR Binary Run Length Encoding (XBRLE) \cite{svardEvaluationDeltaCompression2011}は，
メモリページの差分圧縮を用いて移送を行う手法である．
通常の Pre-copy 手法での移送では，ダーティレートがネットワーク転送速度よりも高い場合，
ダーティページの反復転送が収束せず，移送時間が長期化したり，ダウンタイムが増加するという課題がある．
既存の手法では，移送中の帯域幅を増加させたり，メモリへの書き込みが多いプロセスを一時的に凍結させる
アプローチがある\cite{bradfordLiveWideareaMigration2007}．
しかし，これらは信頼性の低かったり，低速な接続を介したライブ移送が行われる場合に悪化する．
また，VM で稼働中のアプリケーションの性能を悪化させるという欠点がある．
XBRLE は VM のメモリ内状態を転送中に圧縮するというアイデア\cite{hackingImprovingLiveMigration2009}を拡張し，
メモリページに対して差分圧縮を行うことで転送データ量を削減する．
これにより移送スループットを向上させ，ダウンタイムを削減する．

XBRLE では，メモリ上のデータの変更箇所がごく一部であり，
大部分が変化しないという特性を利用し，ページの変更箇所の差分を XOR 演算によって求め，
それを RLE \cite{pountainRunlengthEncoding1987}によって圧縮して転送する手法を採用する．
移送元で差分を求める際，メモリ上にあるページのほかに変更前のページが必要となる．
XBRLE では，移送元ホストのメモリ消費を抑えつつ高速な検索を行うために，
2 ウェイセットアソシアティブ方式のキャッシュ機構を採用する\cite{hillAspectsCacheMemory1987a}．
これにより頻繁に書き換えられるページを保存し，差分計算に使用する．
差分圧縮転送処理の流れとしては，転送対象のページがキャッシュヒットしたら，
新しいバージョンとキャッシュ上の旧バージョンの差分ページを XOR 演算で作成し，
それを RLE によって圧縮したページを移送先に転送する．
移送先で差分圧縮されたページを受信したら，それを解凍して得られた差分ページと
移送先が保持している旧バージョンのページで XOR 演算を行い，新しいバージョンのページを再構築する．

Pre-copy 手法と比較を行った結果，高いメモリ書き換え頻度を発生させるベンチマークを実行した移送において，
総移送時間は 65 秒から 48 秒に減少し (約 26\% 削減)，ダウンタイムは 32 秒から 0.297 秒へと低下した(約 1/100 短縮)．


\section{CPU スケジューリングを用いた最適化 Pre-copy 手法}
本手法は VM のダーティレートを制限し，ライブ移送のパフォーマンス向上を支援する \cite{jinOptimizingLiveMigration2011}．
ライブ移送においてダーティレートが帯域幅に近づくと，
ダウンタイムが急激に増加する移送バリアと呼ばれる現象が発生する．
これにより，非ライブ移送と同等のダウンタイムが発生し，事実上ライブ移送が失敗する．
本研究ではこの問題を緩和するために，ダーティレートを抑制することでライブ移送を最適化する．

提案手法では，ライブ移送中に vCPU を調整することで，強制的にダーティレートを制御する．
このアプローチは，VM のダーティレートが CPU 使用率とほぼ線形関係にあるという経験則\cite{rosenblumVirtualMachineMonitors2005}に基づいている．
反復転送フェーズにおいて，転送速度とダーティレートを計測し，
現在のダーティレートが転送速度を超えそうな場合，新しい vCPU 割り当て率を計算し，
VMM のスケジューラに対して，VM の vCPU 使用率をその値に制限するように要求する．
ただし，サービスの完全停止を防ぐため，割り当て率には一定の下限 (20\%) を設ける．
これにより，各ラウンド中に生成される新たなダーティビットの量を減らすことができ，
最終ラウンドで転送される全体のデータ量を目標値以下に制御する．

実用アプリケーションを用いた実験の結果，ダウンタイムは通常手法の 2491ms に対し，
提案手法は 288ms となり，約 88\% 削減された．


\section{JAVMM}
Java-Aware VM Migration (JAVMM) \cite{houApplicationassistedLiveMigration2015}は
アプリケーションの支援を利用して，移送先でのアプリケーション実行に不要な VM メモリページの
転送をスキップする手法である.
アプリケーションの実行を制限してメモリのダーティレートを低下させるたり，
圧縮転送によってメモリ内容の量を減らすアプローチは，
高いリソースコストやアプリケーションのパフォーマンスへのペナルティを招く．
本手法では，アプリケーションのセマンティクスを活用してメモリ転送量を削減を行う\cite{minhasRemusDBTransparentHigh2013}，
アプリケーション協調型ライブ移送手法を設計する．

JAVMM は Java VM (JVM) の支援を受けて，Java アプリケーションに割り当てられたメモリのうち，
頻繁に更新される young 世代のメモリ領域の転送をスキップすることで転送量を削減する.
JVM はヒープ領域を，新しく生成されたオブジェクトが割り当てられる領域 (Young 世代) と，
長期間生存しているオブジェクトが格納される領域 (Old 世代) に分割して管理している．
このうち Young 世代は短命で頻繁に書き換えられ，その多くがガベージデータであるという特徴を持つ\cite{ungarGenerationScavengingNondisruptlve}．
Young 世代がいっぱいになると，JVM はガーベジコレクション (GC) を実行して，
Young 世代のガベージデータが解放される．
移送時にガベージデータを移送先に転送するより，GC を実行して解放する処理のほうが高速であったため，
JAVMM は移送時に GC を実行して，ガベージデータを解放することで転送量を削減する．

JAVMM では，移送時ゲスト OS 内のカーネルモジュール (LKM) が VMM 連携して動作する．
移送が開始すると JVM から Young 世代の仮想アドレス範囲を取得し，
反復転送フェーズでは Young 世代に含まれるすべてのページのの転送をスキップする．
反復転送フェーズが終了し Stop-and-Copy フェーズに入る直前，
GC を実行しガベージデータの解放を行う．
そして GC で生き残ったデータだけを転送ビットマップに登録し，
Stop-and-Copy フェーズで転送することで，高速かつパフォーマンスへの影響を少なく移送を行う．

JAVMM と従来の Pre-copy 手法と比較した．
その結果，JAVMM は young 世代の領域が大きくなるほど効果が増し，
最大で転送量は 93\% ，移送時間は 91\% ，ダウンタイムは 91\% の削減に成功した．


\section{まとめ}
これらは，異なるアプローチを用いた VM ライブ移送の最適化手法を提案している．
XBRLE は，差分圧縮されたメモリページを転送することで転送データ量を削減し，
移送スループットを向上させ，ダウンタイムを削減する．
CPU スケジューリングを制御する手法は，
vCPU を調整して強制的にダーティレートを制御することでダウンタイムを削減する．
JAVMM は，アプリケーションのセマンティクスを利用してメモリ転送量とダウンタイムを削減する．

しかし，これらの既存手法にはそれぞれ課題が存在する．
XBRLE は差分計算のために移送元ホスト上に過去のページデータを保持する必要があるため，
ホストマシンのメモリリソースを消費する．
また，キャッシュサイズが VM の頻繁に書き換わるメモリに対して不十分な場合，
キャッシュミスが頻発し，移送効率が低下する．
さらに，ページごとの XOR 演算および RLE 圧縮処理は，計算による CPU リソースのオーバーヘッドを伴う．
CPU スケジューラを制御する手法は，移送パフォーマンス向上のために vCPU を制限するため，
移送中に VM 上で実行しているアプリケーションのスループットが低下し，
タスクの完了時間の遅延が生じるというトレードオフがある．
JAVMM は全ての状況で性能が向上するわけではなく，オブジェクトの生存率が高い場合や，
読み取りが集中する状況においては性能が悪化する可能性がある．
オブジェクトの生存率が高い場合においては，
GC を実行しても多くのオブジェクトが生き残り，
それらを Stop-and-Copy フェーズで転送する必要があるため，ダウンタイムが増加してしまう．
また読み取りが集中する状況では，メモリの書き換えが少ないため
従来の Pre-copy 手法でも効率的に移送可能であり，
このような状況では JAVMM で実行する GC が単なるオーバヘッドとなり，ダウンタイムが増加する要因となる．
これらのケースでは GC による転送量削減効果が GC の実行コストを下回り，
移送パフォーマンスが悪化する．

このように，様々なアプローチでライブ移送の最適化を行う手法は存在するが，
DDB のような，大規模なメモリ領域を占有し，かつアプリケーションから参照され続けている
再構築可能なキャッシュデータを，
アプリケーションの性能を維持したまま効果的に削減する手法は確立されていない．
